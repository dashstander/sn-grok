{
 "cells": [
  {
   "cell_type": "raw",
   "id": "303868e9-7b26-4308-a6ba-7c75b1831ef7",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"S~n~ Preliminary Fourier Analysis\"\n",
    "date: \"March 15, 2023\"\n",
    "bibliography: references.bib\n",
    "format: \n",
    "  html:\n",
    "    code-fold: true\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32edf707-de53-4c71-a56a-03f196e5dad2",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### Quick Primer on the Representation Theory of S~n~\n",
    "\n",
    "The irreducible representations (irreps) of $S_{n}$, the symmetric group on $n$ elements, correspond to partitions of $n$. Since $S_n$ is not abelian for $n \\gt 2$, each irrep $\\rho$ corresponds to matrices with differing dimensions. The trivial and alternating representations are the only two one-dimensional representations. The _trivial representation_ corresponds to the partition $(1+1+\\ldots+1)$ and assigns every permutation to $1$. The _alternating representation_ corresponds to the partition $(n)$ and sends even permutations to $1$ and odd permutations to $-1$. Every matrix representation of $S_{n}$ is a direct sum or tensor product of the irreducible representations.\n",
    "\n",
    "Given a function $f: S_{n}\\rightarrow\\mathbb{R}$, the Fourier transform of $f$ maps an irrep of $S_{n}$ to a matrix with the dimension of the irrep, defined as such:\n",
    "$$ \\hat{f}(\\rho) = \\sum_{\\sigma \\in S_{n}} f(\\sigma)\\rho(\\sigma) $$\n",
    "\n",
    "Because $\\hat{f}(\\rho)$ has a different dimension for every $\\rho$, it is harder to visualize than the Fourier transforms over abelian groups. It is worth taking a moment to look at concretely what the transform looks like.\n",
    "\n",
    "Consider $S_{5}$. The transform corresponding to the trivial representation is given by $$\\hat{f}(\\rho_{triv}) = \\sum_{\\sigma \\in S_{5}} f(\\sigma)$$ which is just the unnormalized sum of all of the values of $f$.\n",
    "\n",
    "The transform corresponding to the alternating representation $$\\hat{f}(\\rho_{alt}) =  \\sum_{\\sigma \\in A_{5}} f(\\sigma) - \\sum_{\\sigma \\in S_{5} \\setminus A_{5}} f(\\sigma)$$ is the difference between the values $f$ takes on even versus odd permutations.\n",
    "\n",
    "For the other irreps $\\hat{f}(\\rho)$ is matrix valued and is more difficult to interpret, but we still have a tool to understand $f$ more clearly. As with the traditional Fourier transform we can apply the transform again to recover $f$ from $\\hat{f}$ with the following formula:\n",
    "$$ f(\\sigma) = \\frac{1}{|S_{n}|}\\sum_{\\rho \\in \\mathcal{R}} d_{\\rho}\\operatorname{tr}[\\hat{f}(\\rho)\\rho(\\sigma^{-1})]$$ where the sum over $\\mathcal{R}$ is over all of the partitions of $n$ and $d_{\\rho}$ represents the dimension of the irrep.\n",
    "\n",
    "What we will do is use this fact to consider the set of partitions as a basis for $f(\\sigma)$, and in particular examine the the following vector for a function over $S_{5}$: \n",
    "$$ \\frac{1}{120} \\begin{pmatrix} \\hat{f}(\\rho_{triv}) \\\\ sgn(\\sigma)\\hat{f}(\\rho_{alt}) \\\\ 4 \\cdot \\operatorname{tr}[\\hat{f}(\\rho_{(4, 1)})\\rho_{(4, 1)}(\\sigma^{-1})] \\\\ 5 \\cdot \\operatorname{tr}[\\hat{f}(\\rho_{(3, 2)})\\rho_{(3, 2)}(\\sigma^{-1})] \\\\ 6 \\cdot \\operatorname{tr}[\\hat{f}(\\rho_{(3, 1, 1)})\\rho_{(3, 1, 1)}(\\sigma^{-1})] \\\\ 5 \\cdot \\operatorname{tr}[\\hat{f}(\\rho_{(2, 2, 1)})\\rho_{(2, 2, 1)}(\\sigma^{-1})] \\\\ 4 \\cdot \\operatorname{tr}[\\hat{f}(\\rho_{(2, 1, 1, 1)})\\rho_{(2, 1, 1, 1)}(\\sigma^{-1})] \\end{pmatrix}$$\n",
    "\n",
    "This may not seem to achieve much--we have taken a scalar function and produced a seemingly more complicated vector function. But in practice for many functions only one or two irreps contribute to $f$ and the above vector is sparse. In particular my preliminary investigations show that the activations of an over-parametrized MLP that perfectly learns $S_{5}$ are sparse in the above Fourier basis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d910d867-4bd5-4f91-910a-95efc11ad021",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Set up\n",
    "import math\n",
    "import numpy as np\n",
    "from plotnine import (\n",
    "    ggplot,\n",
    "    aes,\n",
    "    theme, \n",
    "    element_text,\n",
    "    stat_smooth,\n",
    "    facet_wrap,\n",
    "    geom_tile,\n",
    "    geom_point,\n",
    "    geom_histogram,\n",
    "    geom_violin,\n",
    "    geom_col,\n",
    "    xlab,\n",
    "    ylab,\n",
    "    ggtitle\n",
    ")\n",
    "import polars as pl\n",
    "import torch\n",
    "import functorch\n",
    "\n",
    "\n",
    "\n",
    "from sngrok.fourier import slow_ft_1d, slow_ft_2d, sn_fourier_basis, sn_fourier_basis_2d\n",
    "from sngrok.permutations import Permutation, make_permutation_dataset\n",
    "from sngrok.model import SnMLP\n",
    "from sngrok.tableau import generate_partitions\n",
    "from sngrok.irreps import SnIrrep\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f25f8d8e-ccc2-4c59-bb0d-89d010780b93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def fourier_basis_to_df(tensor, n):\n",
    "    group_order, num_irreps, fn_dim = tensor.shape\n",
    "    all_partitions = generate_partitions(n)\n",
    "    permutations = Permutation.full_group(n)\n",
    "    assert len(permutations) == group_order\n",
    "    assert len(all_partitions) == num_irreps\n",
    "    \n",
    "    long_values = tensor.reshape((-1, fn_dim))\n",
    "    group_col= []\n",
    "    for s in permutations:\n",
    "        group_col += [str(s.sigma)] * num_irreps\n",
    "    part_col = [str(p) for p in all_partitions] * group_order\n",
    "    assert len(group_col) == len(part_col) and len(group_col) == long_values.shape[0]\n",
    "    val_data = pl.DataFrame(long_values.detach().numpy(), schema=[f'dim{i}' for i in range(fn_dim)])\n",
    "    sn_metadata = pl.DataFrame({'permutation': group_col, 'irrep': part_col})\n",
    "    return pl.concat([sn_metadata, val_data], how='horizontal')\n",
    "\n",
    "\n",
    "\n",
    "def make_embed_barplot_2d(data, lperm, rperm, irreps, title_prefix):\n",
    "    df = data.filter(\n",
    "          (pl.col('permutation_left') == str(lperm.sigma)) \n",
    "        & (pl.col('permutation_right') == str(rperm.sigma))\n",
    "        #& ((pl.col('irrep_left') == rep[0]) & (pl.col('irrep_right') == rep[1]))\n",
    "    ).rename(\n",
    "        {col: col[3:] for col in linear_df.columns if col.startswith('dim')}\n",
    "    ).melt(\n",
    "        id_vars=['permutation_left', 'permutation_right','irrep_left', 'irrep_right']\n",
    "    ).with_columns(\n",
    "        [pl.col('variable').str.parse_int(radix=10),\n",
    "        (pl.col('irrep_left') + '|' + pl.col('irrep_right')).alias('irrep')]\n",
    "    ).filter(\n",
    "        pl.col('irrep').is_in(irreps)\n",
    "    ).to_pandas()\n",
    "    return (\n",
    "        ggplot(df, aes(x='reorder(factor(variable), np.abs(value))', y='value', fill='irrep')) \n",
    "        + geom_col()\n",
    "        #+ facet_wrap('~variable_group') \n",
    "        + xlab('Linear Dimension')\n",
    "        + ylab('Value')\n",
    "        + ggtitle(f'{title_prefix}: {str(lperm.sigma)}  v. {rperm.sigma}')\n",
    "        + theme(axis_text_x=element_text(rotation=60, hjust=1))\n",
    "    )\n",
    "\n",
    "\n",
    "def make_embed_scatterplot(data, mindim, maxdim):\n",
    "    filtered_df = data.filter(\n",
    "        pl.col('conjugacy_class') != '(1, 1, 1, 1, 1)'\n",
    "    ).filter(pl.col('embed_dim') < maxdim).filter(pl.col('embed_dim') >= mindim)\n",
    "\n",
    "    return (ggplot(\n",
    "        filtered_df.to_pandas(),\n",
    "        aes(x='(5,)', y='(2, 1, 1, 1)', fill='parity')) \n",
    "     + geom_point() \n",
    "     + facet_wrap('~embed_dim', nrow=4)\n",
    "     + xlab('Sign Representation')\n",
    "     + ylab('Standard X Sign Representation')\n",
    "     + ggtitle(f'S5 Left Embedding Dims {mindim}-{maxdim - 1}')\n",
    "    )\n",
    "\n",
    "\n",
    "def calc_power_contributions(tensor, n):\n",
    "    total_power = (tensor ** 2).mean(dim=0)\n",
    "    fourier_transform = slow_ft_1d(tensor, n)\n",
    "    irrep_power = calc_power(fourier_transform, math.factorial(n))\n",
    "    power_contribs = {irrep: power / total_power for irrep, power in irrep_power.items()}\n",
    "    irreps = list(power_contribs.keys())\n",
    "    power_vals = torch.cat([power_contribs[irrep].unsqueeze(0) for irrep in irreps], dim=0)\n",
    "    val_data = pl.DataFrame(power_vals.detach().numpy(), schema=[f'dim{i}' for i in range(256)])\n",
    "    val_data.insert_at_idx(0, pl.Series('irrep', [str(i) for i in irreps]))\n",
    "    return val_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2a617e2-1ba3-4398-b815-65c86194208d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Load Model\n",
    "\n",
    "run = torch.load('checkpoints/s5_50_02/full_run.pth', map_location=torch.device('cpu'))\n",
    "model = SnMLP.from_config(run['config'])\n",
    "model.load_state_dict(run['model'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770d36d2-e0ec-486a-89f5-46f58967fc85",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "### Power Spectrum\n",
    "\n",
    "The model has learned two 256 dimensional representations for each for permutation, one for when that permutation appears on the left and one for the right. We apply the above framework by treating each embedding as a function $S_{5} \\rightarrow \\mathbb{R}^{256}$ and applying the Fourier transform elementwise across the embedding dimension.\n",
    "\n",
    "We can see that across dimensions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24926071-1dec-457c-96c7-60145bf11638",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fourier_lembed = slow_ft_1d(model.lembed.weight.to(torch.float64), 5)\n",
    "fourier_rembed = slow_ft_1d(model.rembed.weight.to(torch.float64), 5)\n",
    "\n",
    "ft_decomp_lembed = sn_fourier_basis(fourier_lembed, 5)\n",
    "ft_decomp_rembed = sn_fourier_basis(fourier_rembed, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb85e5ad-d91b-4fef-854a-7961bbc09647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sngrok.fourier import calc_power\n",
    "\n",
    "power_lembed = calc_power(fourier_lembed, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a78c5038-1d2a-4798-8d3a-1ef56965e7fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0076, dtype=torch.float64, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_lembed[(3, 2)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d72cb4d-4cd3-402d-9f62-da753f923767",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db6cf572-a2f5-4e57-a45f-b0285353888c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       ".pl-dataframe > thead > tr > th {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<table border=\"1\" class=\"pl-dataframe\">\n",
       "<small>shape: (5, 257)</small>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "irrep\n",
       "</th>\n",
       "<th>\n",
       "dim0\n",
       "</th>\n",
       "<th>\n",
       "dim1\n",
       "</th>\n",
       "<th>\n",
       "dim2\n",
       "</th>\n",
       "<th>\n",
       "dim3\n",
       "</th>\n",
       "<th>\n",
       "dim4\n",
       "</th>\n",
       "<th>\n",
       "dim5\n",
       "</th>\n",
       "<th>\n",
       "dim6\n",
       "</th>\n",
       "<th>\n",
       "dim7\n",
       "</th>\n",
       "<th>\n",
       "dim8\n",
       "</th>\n",
       "<th>\n",
       "dim9\n",
       "</th>\n",
       "<th>\n",
       "dim10\n",
       "</th>\n",
       "<th>\n",
       "dim11\n",
       "</th>\n",
       "<th>\n",
       "dim12\n",
       "</th>\n",
       "<th>\n",
       "dim13\n",
       "</th>\n",
       "<th>\n",
       "dim14\n",
       "</th>\n",
       "<th>\n",
       "dim15\n",
       "</th>\n",
       "<th>\n",
       "dim16\n",
       "</th>\n",
       "<th>\n",
       "dim17\n",
       "</th>\n",
       "<th>\n",
       "dim18\n",
       "</th>\n",
       "<th>\n",
       "dim19\n",
       "</th>\n",
       "<th>\n",
       "dim20\n",
       "</th>\n",
       "<th>\n",
       "dim21\n",
       "</th>\n",
       "<th>\n",
       "dim22\n",
       "</th>\n",
       "<th>\n",
       "dim23\n",
       "</th>\n",
       "<th>\n",
       "dim24\n",
       "</th>\n",
       "<th>\n",
       "dim25\n",
       "</th>\n",
       "<th>\n",
       "dim26\n",
       "</th>\n",
       "<th>\n",
       "dim27\n",
       "</th>\n",
       "<th>\n",
       "dim28\n",
       "</th>\n",
       "<th>\n",
       "dim29\n",
       "</th>\n",
       "<th>\n",
       "dim30\n",
       "</th>\n",
       "<th>\n",
       "dim31\n",
       "</th>\n",
       "<th>\n",
       "dim32\n",
       "</th>\n",
       "<th>\n",
       "dim33\n",
       "</th>\n",
       "<th>\n",
       "dim34\n",
       "</th>\n",
       "<th>\n",
       "dim35\n",
       "</th>\n",
       "<th>\n",
       "...\n",
       "</th>\n",
       "<th>\n",
       "dim219\n",
       "</th>\n",
       "<th>\n",
       "dim220\n",
       "</th>\n",
       "<th>\n",
       "dim221\n",
       "</th>\n",
       "<th>\n",
       "dim222\n",
       "</th>\n",
       "<th>\n",
       "dim223\n",
       "</th>\n",
       "<th>\n",
       "dim224\n",
       "</th>\n",
       "<th>\n",
       "dim225\n",
       "</th>\n",
       "<th>\n",
       "dim226\n",
       "</th>\n",
       "<th>\n",
       "dim227\n",
       "</th>\n",
       "<th>\n",
       "dim228\n",
       "</th>\n",
       "<th>\n",
       "dim229\n",
       "</th>\n",
       "<th>\n",
       "dim230\n",
       "</th>\n",
       "<th>\n",
       "dim231\n",
       "</th>\n",
       "<th>\n",
       "dim232\n",
       "</th>\n",
       "<th>\n",
       "dim233\n",
       "</th>\n",
       "<th>\n",
       "dim234\n",
       "</th>\n",
       "<th>\n",
       "dim235\n",
       "</th>\n",
       "<th>\n",
       "dim236\n",
       "</th>\n",
       "<th>\n",
       "dim237\n",
       "</th>\n",
       "<th>\n",
       "dim238\n",
       "</th>\n",
       "<th>\n",
       "dim239\n",
       "</th>\n",
       "<th>\n",
       "dim240\n",
       "</th>\n",
       "<th>\n",
       "dim241\n",
       "</th>\n",
       "<th>\n",
       "dim242\n",
       "</th>\n",
       "<th>\n",
       "dim243\n",
       "</th>\n",
       "<th>\n",
       "dim244\n",
       "</th>\n",
       "<th>\n",
       "dim245\n",
       "</th>\n",
       "<th>\n",
       "dim246\n",
       "</th>\n",
       "<th>\n",
       "dim247\n",
       "</th>\n",
       "<th>\n",
       "dim248\n",
       "</th>\n",
       "<th>\n",
       "dim249\n",
       "</th>\n",
       "<th>\n",
       "dim250\n",
       "</th>\n",
       "<th>\n",
       "dim251\n",
       "</th>\n",
       "<th>\n",
       "dim252\n",
       "</th>\n",
       "<th>\n",
       "dim253\n",
       "</th>\n",
       "<th>\n",
       "dim254\n",
       "</th>\n",
       "<th>\n",
       "dim255\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "...\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;(1, 1, 1, 1, 1...\n",
       "</td>\n",
       "<td>\n",
       "0.000046\n",
       "</td>\n",
       "<td>\n",
       "0.000099\n",
       "</td>\n",
       "<td>\n",
       "0.000015\n",
       "</td>\n",
       "<td>\n",
       "0.000047\n",
       "</td>\n",
       "<td>\n",
       "0.000032\n",
       "</td>\n",
       "<td>\n",
       "0.000019\n",
       "</td>\n",
       "<td>\n",
       "0.000002\n",
       "</td>\n",
       "<td>\n",
       "0.000003\n",
       "</td>\n",
       "<td>\n",
       "0.000095\n",
       "</td>\n",
       "<td>\n",
       "0.000003\n",
       "</td>\n",
       "<td>\n",
       "2.5411e-8\n",
       "</td>\n",
       "<td>\n",
       "1.6232e-7\n",
       "</td>\n",
       "<td>\n",
       "0.00007\n",
       "</td>\n",
       "<td>\n",
       "0.000042\n",
       "</td>\n",
       "<td>\n",
       "0.000097\n",
       "</td>\n",
       "<td>\n",
       "0.000088\n",
       "</td>\n",
       "<td>\n",
       "0.000002\n",
       "</td>\n",
       "<td>\n",
       "0.000024\n",
       "</td>\n",
       "<td>\n",
       "0.000023\n",
       "</td>\n",
       "<td>\n",
       "0.000002\n",
       "</td>\n",
       "<td>\n",
       "0.000071\n",
       "</td>\n",
       "<td>\n",
       "0.000001\n",
       "</td>\n",
       "<td>\n",
       "0.000294\n",
       "</td>\n",
       "<td>\n",
       "0.000024\n",
       "</td>\n",
       "<td>\n",
       "0.000178\n",
       "</td>\n",
       "<td>\n",
       "0.00013\n",
       "</td>\n",
       "<td>\n",
       "0.000015\n",
       "</td>\n",
       "<td>\n",
       "0.00007\n",
       "</td>\n",
       "<td>\n",
       "0.000407\n",
       "</td>\n",
       "<td>\n",
       "0.000009\n",
       "</td>\n",
       "<td>\n",
       "0.000104\n",
       "</td>\n",
       "<td>\n",
       "6.3735e-7\n",
       "</td>\n",
       "<td>\n",
       "0.000127\n",
       "</td>\n",
       "<td>\n",
       "0.000227\n",
       "</td>\n",
       "<td>\n",
       "0.000035\n",
       "</td>\n",
       "<td>\n",
       "0.000211\n",
       "</td>\n",
       "<td>\n",
       "...\n",
       "</td>\n",
       "<td>\n",
       "0.000164\n",
       "</td>\n",
       "<td>\n",
       "0.000011\n",
       "</td>\n",
       "<td>\n",
       "0.000003\n",
       "</td>\n",
       "<td>\n",
       "0.00001\n",
       "</td>\n",
       "<td>\n",
       "0.000015\n",
       "</td>\n",
       "<td>\n",
       "8.4680e-7\n",
       "</td>\n",
       "<td>\n",
       "0.000007\n",
       "</td>\n",
       "<td>\n",
       "0.000031\n",
       "</td>\n",
       "<td>\n",
       "0.000024\n",
       "</td>\n",
       "<td>\n",
       "0.000004\n",
       "</td>\n",
       "<td>\n",
       "0.000033\n",
       "</td>\n",
       "<td>\n",
       "0.000011\n",
       "</td>\n",
       "<td>\n",
       "0.000001\n",
       "</td>\n",
       "<td>\n",
       "3.6381e-8\n",
       "</td>\n",
       "<td>\n",
       "0.00001\n",
       "</td>\n",
       "<td>\n",
       "0.000001\n",
       "</td>\n",
       "<td>\n",
       "0.00001\n",
       "</td>\n",
       "<td>\n",
       "0.000003\n",
       "</td>\n",
       "<td>\n",
       "0.000004\n",
       "</td>\n",
       "<td>\n",
       "0.0001\n",
       "</td>\n",
       "<td>\n",
       "0.000017\n",
       "</td>\n",
       "<td>\n",
       "0.000012\n",
       "</td>\n",
       "<td>\n",
       "0.000105\n",
       "</td>\n",
       "<td>\n",
       "0.000003\n",
       "</td>\n",
       "<td>\n",
       "0.000069\n",
       "</td>\n",
       "<td>\n",
       "0.000029\n",
       "</td>\n",
       "<td>\n",
       "0.000001\n",
       "</td>\n",
       "<td>\n",
       "0.000073\n",
       "</td>\n",
       "<td>\n",
       "0.000009\n",
       "</td>\n",
       "<td>\n",
       "0.000003\n",
       "</td>\n",
       "<td>\n",
       "0.000073\n",
       "</td>\n",
       "<td>\n",
       "0.000154\n",
       "</td>\n",
       "<td>\n",
       "0.000089\n",
       "</td>\n",
       "<td>\n",
       "5.1512e-9\n",
       "</td>\n",
       "<td>\n",
       "0.000006\n",
       "</td>\n",
       "<td>\n",
       "0.000066\n",
       "</td>\n",
       "<td>\n",
       "0.000153\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;(2, 1, 1, 1)&quot;\n",
       "</td>\n",
       "<td>\n",
       "0.675678\n",
       "</td>\n",
       "<td>\n",
       "0.724933\n",
       "</td>\n",
       "<td>\n",
       "0.695858\n",
       "</td>\n",
       "<td>\n",
       "0.690677\n",
       "</td>\n",
       "<td>\n",
       "0.704629\n",
       "</td>\n",
       "<td>\n",
       "0.661537\n",
       "</td>\n",
       "<td>\n",
       "0.736582\n",
       "</td>\n",
       "<td>\n",
       "0.711023\n",
       "</td>\n",
       "<td>\n",
       "0.705652\n",
       "</td>\n",
       "<td>\n",
       "0.729387\n",
       "</td>\n",
       "<td>\n",
       "0.711931\n",
       "</td>\n",
       "<td>\n",
       "0.69801\n",
       "</td>\n",
       "<td>\n",
       "0.760167\n",
       "</td>\n",
       "<td>\n",
       "0.703564\n",
       "</td>\n",
       "<td>\n",
       "0.786631\n",
       "</td>\n",
       "<td>\n",
       "0.648364\n",
       "</td>\n",
       "<td>\n",
       "0.667896\n",
       "</td>\n",
       "<td>\n",
       "0.724582\n",
       "</td>\n",
       "<td>\n",
       "0.695396\n",
       "</td>\n",
       "<td>\n",
       "0.705606\n",
       "</td>\n",
       "<td>\n",
       "0.695161\n",
       "</td>\n",
       "<td>\n",
       "0.767054\n",
       "</td>\n",
       "<td>\n",
       "0.743521\n",
       "</td>\n",
       "<td>\n",
       "0.6783\n",
       "</td>\n",
       "<td>\n",
       "0.688975\n",
       "</td>\n",
       "<td>\n",
       "0.687225\n",
       "</td>\n",
       "<td>\n",
       "0.669359\n",
       "</td>\n",
       "<td>\n",
       "0.736762\n",
       "</td>\n",
       "<td>\n",
       "0.688411\n",
       "</td>\n",
       "<td>\n",
       "0.711185\n",
       "</td>\n",
       "<td>\n",
       "0.673649\n",
       "</td>\n",
       "<td>\n",
       "0.733194\n",
       "</td>\n",
       "<td>\n",
       "0.716211\n",
       "</td>\n",
       "<td>\n",
       "0.631553\n",
       "</td>\n",
       "<td>\n",
       "0.730782\n",
       "</td>\n",
       "<td>\n",
       "0.710005\n",
       "</td>\n",
       "<td>\n",
       "...\n",
       "</td>\n",
       "<td>\n",
       "0.75694\n",
       "</td>\n",
       "<td>\n",
       "0.673177\n",
       "</td>\n",
       "<td>\n",
       "0.716001\n",
       "</td>\n",
       "<td>\n",
       "0.72964\n",
       "</td>\n",
       "<td>\n",
       "0.68207\n",
       "</td>\n",
       "<td>\n",
       "0.698266\n",
       "</td>\n",
       "<td>\n",
       "0.660595\n",
       "</td>\n",
       "<td>\n",
       "0.760719\n",
       "</td>\n",
       "<td>\n",
       "0.738464\n",
       "</td>\n",
       "<td>\n",
       "0.69224\n",
       "</td>\n",
       "<td>\n",
       "0.719544\n",
       "</td>\n",
       "<td>\n",
       "0.703416\n",
       "</td>\n",
       "<td>\n",
       "0.668658\n",
       "</td>\n",
       "<td>\n",
       "0.731027\n",
       "</td>\n",
       "<td>\n",
       "0.725379\n",
       "</td>\n",
       "<td>\n",
       "0.709873\n",
       "</td>\n",
       "<td>\n",
       "0.734869\n",
       "</td>\n",
       "<td>\n",
       "0.707375\n",
       "</td>\n",
       "<td>\n",
       "0.73114\n",
       "</td>\n",
       "<td>\n",
       "0.70468\n",
       "</td>\n",
       "<td>\n",
       "0.701455\n",
       "</td>\n",
       "<td>\n",
       "0.735725\n",
       "</td>\n",
       "<td>\n",
       "0.706958\n",
       "</td>\n",
       "<td>\n",
       "0.682519\n",
       "</td>\n",
       "<td>\n",
       "0.629804\n",
       "</td>\n",
       "<td>\n",
       "0.679398\n",
       "</td>\n",
       "<td>\n",
       "0.748716\n",
       "</td>\n",
       "<td>\n",
       "0.68072\n",
       "</td>\n",
       "<td>\n",
       "0.692222\n",
       "</td>\n",
       "<td>\n",
       "0.774579\n",
       "</td>\n",
       "<td>\n",
       "0.682863\n",
       "</td>\n",
       "<td>\n",
       "0.690459\n",
       "</td>\n",
       "<td>\n",
       "0.687915\n",
       "</td>\n",
       "<td>\n",
       "0.7556\n",
       "</td>\n",
       "<td>\n",
       "0.749997\n",
       "</td>\n",
       "<td>\n",
       "0.793774\n",
       "</td>\n",
       "<td>\n",
       "0.751264\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;(2, 2, 1)&quot;\n",
       "</td>\n",
       "<td>\n",
       "0.03058\n",
       "</td>\n",
       "<td>\n",
       "0.037389\n",
       "</td>\n",
       "<td>\n",
       "0.014814\n",
       "</td>\n",
       "<td>\n",
       "0.046671\n",
       "</td>\n",
       "<td>\n",
       "0.040058\n",
       "</td>\n",
       "<td>\n",
       "0.048579\n",
       "</td>\n",
       "<td>\n",
       "0.032511\n",
       "</td>\n",
       "<td>\n",
       "0.01666\n",
       "</td>\n",
       "<td>\n",
       "0.056324\n",
       "</td>\n",
       "<td>\n",
       "0.045886\n",
       "</td>\n",
       "<td>\n",
       "0.037353\n",
       "</td>\n",
       "<td>\n",
       "0.050777\n",
       "</td>\n",
       "<td>\n",
       "0.049803\n",
       "</td>\n",
       "<td>\n",
       "0.044192\n",
       "</td>\n",
       "<td>\n",
       "0.041545\n",
       "</td>\n",
       "<td>\n",
       "0.036159\n",
       "</td>\n",
       "<td>\n",
       "0.073048\n",
       "</td>\n",
       "<td>\n",
       "0.041804\n",
       "</td>\n",
       "<td>\n",
       "0.038774\n",
       "</td>\n",
       "<td>\n",
       "0.032285\n",
       "</td>\n",
       "<td>\n",
       "0.057398\n",
       "</td>\n",
       "<td>\n",
       "0.059959\n",
       "</td>\n",
       "<td>\n",
       "0.036359\n",
       "</td>\n",
       "<td>\n",
       "0.033412\n",
       "</td>\n",
       "<td>\n",
       "0.038436\n",
       "</td>\n",
       "<td>\n",
       "0.042627\n",
       "</td>\n",
       "<td>\n",
       "0.04126\n",
       "</td>\n",
       "<td>\n",
       "0.030796\n",
       "</td>\n",
       "<td>\n",
       "0.024395\n",
       "</td>\n",
       "<td>\n",
       "0.036324\n",
       "</td>\n",
       "<td>\n",
       "0.047792\n",
       "</td>\n",
       "<td>\n",
       "0.028013\n",
       "</td>\n",
       "<td>\n",
       "0.033244\n",
       "</td>\n",
       "<td>\n",
       "0.065071\n",
       "</td>\n",
       "<td>\n",
       "0.044175\n",
       "</td>\n",
       "<td>\n",
       "0.052924\n",
       "</td>\n",
       "<td>\n",
       "...\n",
       "</td>\n",
       "<td>\n",
       "0.03387\n",
       "</td>\n",
       "<td>\n",
       "0.045869\n",
       "</td>\n",
       "<td>\n",
       "0.047499\n",
       "</td>\n",
       "<td>\n",
       "0.041335\n",
       "</td>\n",
       "<td>\n",
       "0.032175\n",
       "</td>\n",
       "<td>\n",
       "0.07111\n",
       "</td>\n",
       "<td>\n",
       "0.054849\n",
       "</td>\n",
       "<td>\n",
       "0.054159\n",
       "</td>\n",
       "<td>\n",
       "0.026552\n",
       "</td>\n",
       "<td>\n",
       "0.050258\n",
       "</td>\n",
       "<td>\n",
       "0.055173\n",
       "</td>\n",
       "<td>\n",
       "0.041586\n",
       "</td>\n",
       "<td>\n",
       "0.034071\n",
       "</td>\n",
       "<td>\n",
       "0.03749\n",
       "</td>\n",
       "<td>\n",
       "0.038819\n",
       "</td>\n",
       "<td>\n",
       "0.04403\n",
       "</td>\n",
       "<td>\n",
       "0.036829\n",
       "</td>\n",
       "<td>\n",
       "0.054429\n",
       "</td>\n",
       "<td>\n",
       "0.036824\n",
       "</td>\n",
       "<td>\n",
       "0.035848\n",
       "</td>\n",
       "<td>\n",
       "0.029824\n",
       "</td>\n",
       "<td>\n",
       "0.027377\n",
       "</td>\n",
       "<td>\n",
       "0.037252\n",
       "</td>\n",
       "<td>\n",
       "0.072492\n",
       "</td>\n",
       "<td>\n",
       "0.047848\n",
       "</td>\n",
       "<td>\n",
       "0.024103\n",
       "</td>\n",
       "<td>\n",
       "0.041344\n",
       "</td>\n",
       "<td>\n",
       "0.032462\n",
       "</td>\n",
       "<td>\n",
       "0.045061\n",
       "</td>\n",
       "<td>\n",
       "0.041228\n",
       "</td>\n",
       "<td>\n",
       "0.062993\n",
       "</td>\n",
       "<td>\n",
       "0.034685\n",
       "</td>\n",
       "<td>\n",
       "0.04477\n",
       "</td>\n",
       "<td>\n",
       "0.020371\n",
       "</td>\n",
       "<td>\n",
       "0.031216\n",
       "</td>\n",
       "<td>\n",
       "0.031286\n",
       "</td>\n",
       "<td>\n",
       "0.036576\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;(3, 1, 1)&quot;\n",
       "</td>\n",
       "<td>\n",
       "0.00178\n",
       "</td>\n",
       "<td>\n",
       "0.001817\n",
       "</td>\n",
       "<td>\n",
       "0.001847\n",
       "</td>\n",
       "<td>\n",
       "0.002212\n",
       "</td>\n",
       "<td>\n",
       "0.004626\n",
       "</td>\n",
       "<td>\n",
       "0.001628\n",
       "</td>\n",
       "<td>\n",
       "0.001519\n",
       "</td>\n",
       "<td>\n",
       "0.001315\n",
       "</td>\n",
       "<td>\n",
       "0.002488\n",
       "</td>\n",
       "<td>\n",
       "0.002685\n",
       "</td>\n",
       "<td>\n",
       "0.0027\n",
       "</td>\n",
       "<td>\n",
       "0.004896\n",
       "</td>\n",
       "<td>\n",
       "0.004376\n",
       "</td>\n",
       "<td>\n",
       "0.002105\n",
       "</td>\n",
       "<td>\n",
       "0.00431\n",
       "</td>\n",
       "<td>\n",
       "0.002671\n",
       "</td>\n",
       "<td>\n",
       "0.004072\n",
       "</td>\n",
       "<td>\n",
       "0.003309\n",
       "</td>\n",
       "<td>\n",
       "0.001897\n",
       "</td>\n",
       "<td>\n",
       "0.002257\n",
       "</td>\n",
       "<td>\n",
       "0.002986\n",
       "</td>\n",
       "<td>\n",
       "0.003309\n",
       "</td>\n",
       "<td>\n",
       "0.001337\n",
       "</td>\n",
       "<td>\n",
       "0.001685\n",
       "</td>\n",
       "<td>\n",
       "0.003376\n",
       "</td>\n",
       "<td>\n",
       "0.002168\n",
       "</td>\n",
       "<td>\n",
       "0.003169\n",
       "</td>\n",
       "<td>\n",
       "0.002716\n",
       "</td>\n",
       "<td>\n",
       "0.002048\n",
       "</td>\n",
       "<td>\n",
       "0.001318\n",
       "</td>\n",
       "<td>\n",
       "0.0019\n",
       "</td>\n",
       "<td>\n",
       "0.002164\n",
       "</td>\n",
       "<td>\n",
       "0.002156\n",
       "</td>\n",
       "<td>\n",
       "0.002766\n",
       "</td>\n",
       "<td>\n",
       "0.002215\n",
       "</td>\n",
       "<td>\n",
       "0.003528\n",
       "</td>\n",
       "<td>\n",
       "...\n",
       "</td>\n",
       "<td>\n",
       "0.001485\n",
       "</td>\n",
       "<td>\n",
       "0.003158\n",
       "</td>\n",
       "<td>\n",
       "0.001812\n",
       "</td>\n",
       "<td>\n",
       "0.002939\n",
       "</td>\n",
       "<td>\n",
       "0.002218\n",
       "</td>\n",
       "<td>\n",
       "0.002432\n",
       "</td>\n",
       "<td>\n",
       "0.004419\n",
       "</td>\n",
       "<td>\n",
       "0.00309\n",
       "</td>\n",
       "<td>\n",
       "0.001655\n",
       "</td>\n",
       "<td>\n",
       "0.002066\n",
       "</td>\n",
       "<td>\n",
       "0.002954\n",
       "</td>\n",
       "<td>\n",
       "0.003774\n",
       "</td>\n",
       "<td>\n",
       "0.00296\n",
       "</td>\n",
       "<td>\n",
       "0.001418\n",
       "</td>\n",
       "<td>\n",
       "0.002476\n",
       "</td>\n",
       "<td>\n",
       "0.002117\n",
       "</td>\n",
       "<td>\n",
       "0.00226\n",
       "</td>\n",
       "<td>\n",
       "0.001908\n",
       "</td>\n",
       "<td>\n",
       "0.002476\n",
       "</td>\n",
       "<td>\n",
       "0.002897\n",
       "</td>\n",
       "<td>\n",
       "0.001354\n",
       "</td>\n",
       "<td>\n",
       "0.002851\n",
       "</td>\n",
       "<td>\n",
       "0.001883\n",
       "</td>\n",
       "<td>\n",
       "0.006171\n",
       "</td>\n",
       "<td>\n",
       "0.003767\n",
       "</td>\n",
       "<td>\n",
       "0.003573\n",
       "</td>\n",
       "<td>\n",
       "0.002429\n",
       "</td>\n",
       "<td>\n",
       "0.002021\n",
       "</td>\n",
       "<td>\n",
       "0.00275\n",
       "</td>\n",
       "<td>\n",
       "0.003377\n",
       "</td>\n",
       "<td>\n",
       "0.002145\n",
       "</td>\n",
       "<td>\n",
       "0.003017\n",
       "</td>\n",
       "<td>\n",
       "0.003235\n",
       "</td>\n",
       "<td>\n",
       "0.002742\n",
       "</td>\n",
       "<td>\n",
       "0.00172\n",
       "</td>\n",
       "<td>\n",
       "0.001588\n",
       "</td>\n",
       "<td>\n",
       "0.0025\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;(3, 2)&quot;\n",
       "</td>\n",
       "<td>\n",
       "0.205713\n",
       "</td>\n",
       "<td>\n",
       "0.156169\n",
       "</td>\n",
       "<td>\n",
       "0.201507\n",
       "</td>\n",
       "<td>\n",
       "0.172569\n",
       "</td>\n",
       "<td>\n",
       "0.15397\n",
       "</td>\n",
       "<td>\n",
       "0.210685\n",
       "</td>\n",
       "<td>\n",
       "0.147528\n",
       "</td>\n",
       "<td>\n",
       "0.196586\n",
       "</td>\n",
       "<td>\n",
       "0.153487\n",
       "</td>\n",
       "<td>\n",
       "0.141559\n",
       "</td>\n",
       "<td>\n",
       "0.180425\n",
       "</td>\n",
       "<td>\n",
       "0.148684\n",
       "</td>\n",
       "<td>\n",
       "0.08832\n",
       "</td>\n",
       "<td>\n",
       "0.176209\n",
       "</td>\n",
       "<td>\n",
       "0.066068\n",
       "</td>\n",
       "<td>\n",
       "0.20112\n",
       "</td>\n",
       "<td>\n",
       "0.150206\n",
       "</td>\n",
       "<td>\n",
       "0.145743\n",
       "</td>\n",
       "<td>\n",
       "0.186058\n",
       "</td>\n",
       "<td>\n",
       "0.19488\n",
       "</td>\n",
       "<td>\n",
       "0.163121\n",
       "</td>\n",
       "<td>\n",
       "0.114406\n",
       "</td>\n",
       "<td>\n",
       "0.160742\n",
       "</td>\n",
       "<td>\n",
       "0.168041\n",
       "</td>\n",
       "<td>\n",
       "0.165151\n",
       "</td>\n",
       "<td>\n",
       "0.184567\n",
       "</td>\n",
       "<td>\n",
       "0.181094\n",
       "</td>\n",
       "<td>\n",
       "0.159689\n",
       "</td>\n",
       "<td>\n",
       "0.20008\n",
       "</td>\n",
       "<td>\n",
       "0.167835\n",
       "</td>\n",
       "<td>\n",
       "0.179718\n",
       "</td>\n",
       "<td>\n",
       "0.151073\n",
       "</td>\n",
       "<td>\n",
       "0.18217\n",
       "</td>\n",
       "<td>\n",
       "0.20291\n",
       "</td>\n",
       "<td>\n",
       "0.165817\n",
       "</td>\n",
       "<td>\n",
       "0.150962\n",
       "</td>\n",
       "<td>\n",
       "...\n",
       "</td>\n",
       "<td>\n",
       "0.149783\n",
       "</td>\n",
       "<td>\n",
       "0.187624\n",
       "</td>\n",
       "<td>\n",
       "0.135668\n",
       "</td>\n",
       "<td>\n",
       "0.164124\n",
       "</td>\n",
       "<td>\n",
       "0.178504\n",
       "</td>\n",
       "<td>\n",
       "0.135741\n",
       "</td>\n",
       "<td>\n",
       "0.157427\n",
       "</td>\n",
       "<td>\n",
       "0.09937\n",
       "</td>\n",
       "<td>\n",
       "0.156623\n",
       "</td>\n",
       "<td>\n",
       "0.167464\n",
       "</td>\n",
       "<td>\n",
       "0.132191\n",
       "</td>\n",
       "<td>\n",
       "0.146172\n",
       "</td>\n",
       "<td>\n",
       "0.194174\n",
       "</td>\n",
       "<td>\n",
       "0.15275\n",
       "</td>\n",
       "<td>\n",
       "0.155534\n",
       "</td>\n",
       "<td>\n",
       "0.173844\n",
       "</td>\n",
       "<td>\n",
       "0.140955\n",
       "</td>\n",
       "<td>\n",
       "0.149466\n",
       "</td>\n",
       "<td>\n",
       "0.148212\n",
       "</td>\n",
       "<td>\n",
       "0.161624\n",
       "</td>\n",
       "<td>\n",
       "0.176166\n",
       "</td>\n",
       "<td>\n",
       "0.142885\n",
       "</td>\n",
       "<td>\n",
       "0.183668\n",
       "</td>\n",
       "<td>\n",
       "0.153517\n",
       "</td>\n",
       "<td>\n",
       "0.22011\n",
       "</td>\n",
       "<td>\n",
       "0.194091\n",
       "</td>\n",
       "<td>\n",
       "0.129498\n",
       "</td>\n",
       "<td>\n",
       "0.19937\n",
       "</td>\n",
       "<td>\n",
       "0.177043\n",
       "</td>\n",
       "<td>\n",
       "0.08872\n",
       "</td>\n",
       "<td>\n",
       "0.162067\n",
       "</td>\n",
       "<td>\n",
       "0.191046\n",
       "</td>\n",
       "<td>\n",
       "0.165376\n",
       "</td>\n",
       "<td>\n",
       "0.13255\n",
       "</td>\n",
       "<td>\n",
       "0.138513\n",
       "</td>\n",
       "<td>\n",
       "0.102326\n",
       "</td>\n",
       "<td>\n",
       "0.13264\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (5, 257)\n",
       "┌──────────────┬──────────┬──────────┬──────────┬─────┬───────────┬──────────┬──────────┬──────────┐\n",
       "│ irrep        ┆ dim0     ┆ dim1     ┆ dim2     ┆ ... ┆ dim252    ┆ dim253   ┆ dim254   ┆ dim255   │\n",
       "│ ---          ┆ ---      ┆ ---      ┆ ---      ┆     ┆ ---       ┆ ---      ┆ ---      ┆ ---      │\n",
       "│ str          ┆ f64      ┆ f64      ┆ f64      ┆     ┆ f64       ┆ f64      ┆ f64      ┆ f64      │\n",
       "╞══════════════╪══════════╪══════════╪══════════╪═════╪═══════════╪══════════╪══════════╪══════════╡\n",
       "│ (1, 1, 1, 1, ┆ 0.000046 ┆ 0.000099 ┆ 0.000015 ┆ ... ┆ 5.1512e-9 ┆ 0.000006 ┆ 0.000066 ┆ 0.000153 │\n",
       "│ 1)           ┆          ┆          ┆          ┆     ┆           ┆          ┆          ┆          │\n",
       "│ (2, 1, 1, 1) ┆ 0.675678 ┆ 0.724933 ┆ 0.695858 ┆ ... ┆ 0.7556    ┆ 0.749997 ┆ 0.793774 ┆ 0.751264 │\n",
       "│ (2, 2, 1)    ┆ 0.03058  ┆ 0.037389 ┆ 0.014814 ┆ ... ┆ 0.020371  ┆ 0.031216 ┆ 0.031286 ┆ 0.036576 │\n",
       "│ (3, 1, 1)    ┆ 0.00178  ┆ 0.001817 ┆ 0.001847 ┆ ... ┆ 0.002742  ┆ 0.00172  ┆ 0.001588 ┆ 0.0025   │\n",
       "│ (3, 2)       ┆ 0.205713 ┆ 0.156169 ┆ 0.201507 ┆ ... ┆ 0.13255   ┆ 0.138513 ┆ 0.102326 ┆ 0.13264  │\n",
       "└──────────────┴──────────┴──────────┴──────────┴─────┴───────────┴──────────┴──────────┴──────────┘"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "power_vals = torch.cat([power_contribs[irrep].unsqueeze(0) for irrep in irreps], dim=0)\n",
    "val_data = pl.DataFrame(power_vals.detach().numpy(), schema=[f'dim{i}' for i in range(256)])\n",
    "val_data.insert_at_idx(0, pl.Series('irrep', [str(i) for i in irreps]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f48b1bd3-d8ee-4a1e-b220-dd22e15f3879",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       ".pl-dataframe > thead > tr > th {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<table border=\"1\" class=\"pl-dataframe\">\n",
       "<small>shape: (5, 3)</small>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "irrep\n",
       "</th>\n",
       "<th>\n",
       "variable\n",
       "</th>\n",
       "<th>\n",
       "value\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;(1, 1, 1, 1, 1...\n",
       "</td>\n",
       "<td>\n",
       "&quot;dim0&quot;\n",
       "</td>\n",
       "<td>\n",
       "0.000046\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;(2, 1, 1, 1)&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;dim0&quot;\n",
       "</td>\n",
       "<td>\n",
       "0.675678\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;(2, 2, 1)&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;dim0&quot;\n",
       "</td>\n",
       "<td>\n",
       "0.03058\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;(3, 1, 1)&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;dim0&quot;\n",
       "</td>\n",
       "<td>\n",
       "0.00178\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;(3, 2)&quot;\n",
       "</td>\n",
       "<td>\n",
       "&quot;dim0&quot;\n",
       "</td>\n",
       "<td>\n",
       "0.205713\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌─────────────────┬──────────┬──────────┐\n",
       "│ irrep           ┆ variable ┆ value    │\n",
       "│ ---             ┆ ---      ┆ ---      │\n",
       "│ str             ┆ str      ┆ f64      │\n",
       "╞═════════════════╪══════════╪══════════╡\n",
       "│ (1, 1, 1, 1, 1) ┆ dim0     ┆ 0.000046 │\n",
       "│ (2, 1, 1, 1)    ┆ dim0     ┆ 0.675678 │\n",
       "│ (2, 2, 1)       ┆ dim0     ┆ 0.03058  │\n",
       "│ (3, 1, 1)       ┆ dim0     ┆ 0.00178  │\n",
       "│ (3, 2)          ┆ dim0     ┆ 0.205713 │\n",
       "└─────────────────┴──────────┴──────────┘"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.melt(id_vars='irrep').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0984ab03-2218-4a30-892c-64339c88b578",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (393844866)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from plotnine import geom_boxplot \n",
    "ggplot(val_data.melt(id_vars='irrep'), aes(x='irrep', y='value')) + geom_boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7aa56380-79ee-4dec-b48e-ce73425e0d74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m     val_data\u001b[38;5;241m.\u001b[39minsert_at_idx(\u001b[38;5;241m0\u001b[39m, pl\u001b[38;5;241m.\u001b[39mSeries(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mirrep\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m irreps]))\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m val_data, fourier_transform\n\u001b[0;32m---> 17\u001b[0m rval_data \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_power_contributions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrembed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m ggplot(rval_data\u001b[38;5;241m.\u001b[39mmelt(id_vars\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mirrep\u001b[39m\u001b[38;5;124m'\u001b[39m), aes(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mirrep\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;241m+\u001b[39m geom_boxplot()\n",
      "Cell \u001b[0;32mIn[40], line 8\u001b[0m, in \u001b[0;36mcalc_power_contributions\u001b[0;34m(tensor, n)\u001b[0m\n\u001b[1;32m      6\u001b[0m total_power \u001b[38;5;241m=\u001b[39m (tensor \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      7\u001b[0m fourier_transform \u001b[38;5;241m=\u001b[39m slow_ft_1d(tensor, n)\n\u001b[0;32m----> 8\u001b[0m irrep_power \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_power\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfourier_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m power_contribs \u001b[38;5;241m=\u001b[39m {irrep: power \u001b[38;5;241m/\u001b[39m total_power \u001b[38;5;28;01mfor\u001b[39;00m irrep, power \u001b[38;5;129;01min\u001b[39;00m irrep_power\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     10\u001b[0m irreps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(power_contribs\u001b[38;5;241m.\u001b[39mkeys())\n",
      "Cell \u001b[0;32mIn[40], line 2\u001b[0m, in \u001b[0;36mcalc_power\u001b[0;34m(ft, group_order)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalc_power\u001b[39m(ft, group_order):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {k: (frob(v) \u001b[38;5;241m/\u001b[39m group_order\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m ft\u001b[38;5;241m.\u001b[39mitems()}\n",
      "Cell \u001b[0;32mIn[40], line 2\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalc_power\u001b[39m(ft, group_order):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {k: (\u001b[43mfrob\u001b[49m(v) \u001b[38;5;241m/\u001b[39m group_order\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m ft\u001b[38;5;241m.\u001b[39mitems()}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'frob' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def calc_power_contributions(tensor, n):\n",
    "    total_power = (tensor ** 2).mean(dim=0)\n",
    "    fourier_transform = slow_ft_1d(tensor, n)\n",
    "    irrep_power = calc_power(fourier_transform, math.factorial(n))\n",
    "    power_contribs = {irrep: power / total_power for irrep, power in irrep_power.items()}\n",
    "    irreps = list(power_contribs.keys())\n",
    "    power_vals = torch.cat([power_contribs[irrep].unsqueeze(0) for irrep in irreps], dim=0)\n",
    "    val_data = pl.DataFrame(power_vals.detach().numpy(), schema=[f'dim{i}' for i in range(256)])\n",
    "    val_data.insert_at_idx(0, pl.Series('irrep', [str(i) for i in irreps]))\n",
    "    return val_data, fourier_transform\n",
    "\n",
    "\n",
    "rval_data = calc_power_contributions(model.rembed.weight.to(torch.float64), 5)\n",
    "\n",
    "ggplot(rval_data.melt(id_vars='irrep'), aes(x='irrep', y='value')) + geom_boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b783395-f1f1-4dd6-be70-f560f0cbfbf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
